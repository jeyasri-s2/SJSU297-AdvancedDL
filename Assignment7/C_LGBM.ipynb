{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C_LGBM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeyasri-s2/SJSU297-AdvancedDL/blob/master/Assignment7/C_LGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UATAPVTIp_ts"
      },
      "source": [
        "# Goal\n",
        "## Implement lightgbm - do gridsearch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cClMMSfyUMpm"
      },
      "source": [
        "https://www.kaggle.com/fabiendaniel/detecting-malwares-with-lgbm\r\n",
        "Download the csv from this link. ^"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AgPW9ukeTDyk",
        "outputId": "8a100434-3356-491c-82a9-2cf0587aeb19"
      },
      "source": [
        "import numpy as np \r\n",
        "import pandas as pd \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import lightgbm as lgb\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "import warnings\r\n",
        "import gc\r\n",
        "import time\r\n",
        "import sys\r\n",
        "import datetime\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "from tqdm import tqdm\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\r\n",
        "from sklearn import metrics\r\n",
        "# Plotly library\r\n",
        "from plotly.offline import init_notebook_mode, iplot\r\n",
        "import plotly.graph_objs as go\r\n",
        "from plotly import tools\r\n",
        "init_notebook_mode(connected=True)\r\n",
        "pd.set_option('display.max_columns', 500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dl2a8ZCTPt3"
      },
      "source": [
        "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\r\n",
        "numerical_columns = [c for c,v in dtypes.items() if v in numerics]\r\n",
        "categorical_columns = [c for c,v in dtypes.items() if v not in numerics]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoxc5zplTSbW"
      },
      "source": [
        "nrows = 4000000\r\n",
        "#_______________________________________________________________________________\r\n",
        "retained_columns = numerical_columns + categorical_columns\r\n",
        "train = pd.read_csv('../input/train.csv',\r\n",
        "                    nrows = nrows,\r\n",
        "                    usecols = retained_columns,\r\n",
        "                    dtype = dtypes)\r\n",
        "#_______________________________________________________________\r\n",
        "retained_columns += ['MachineIdentifier']\r\n",
        "retained_columns.remove('HasDetections')\r\n",
        "test = pd.read_csv('../input/test.csv',\r\n",
        "                   usecols = retained_columns,\r\n",
        "                   dtype = dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCMZwmd9TU23"
      },
      "source": [
        "true_numerical_columns = [\r\n",
        "    'Census_ProcessorCoreCount',\r\n",
        "    'Census_PrimaryDiskTotalCapacity',\r\n",
        "    'Census_SystemVolumeTotalCapacity',\r\n",
        "    'Census_TotalPhysicalRAM',\r\n",
        "    'Census_InternalPrimaryDiagonalDisplaySizeInInches',\r\n",
        "    'Census_InternalPrimaryDisplayResolutionHorizontal',\r\n",
        "    'Census_InternalPrimaryDisplayResolutionVertical',\r\n",
        "    'Census_InternalBatteryNumberOfCharges'\r\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBp8xm6TTXW_"
      },
      "source": [
        "binary_variables = [c for c in train.columns if train[c].nunique() == 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMQ25LttTb-u"
      },
      "source": [
        "categorical_columns = [c for c in train.columns \r\n",
        "                       if (c not in true_numerical_columns) & (c not in binary_variables)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijGMgZLUTeZW"
      },
      "source": [
        "variables = {\r\n",
        "    'categorical_columns': len(categorical_columns),\r\n",
        "    'binary_variables': len(binary_variables),\r\n",
        "    'true_numerical_columns': len(true_numerical_columns)\r\n",
        "}\r\n",
        "pie_trace = go.Pie(labels=list(variables.keys()), values=list(variables.values()))\r\n",
        "layout = dict(title= \"Variable types\", height=400, width=800)\r\n",
        "fig = dict(data=[pie_trace], layout=layout)\r\n",
        "iplot(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll8jRTwjTkT3"
      },
      "source": [
        "frequency_encoded_variables = [\r\n",
        "    'Census_OEMModelIdentifier',\r\n",
        "    'CityIdentifier',\r\n",
        "    'Census_FirmwareVersionIdentifier',\r\n",
        "    'AvSigVersion',\r\n",
        "    'Census_ProcessorModelIdentifier',\r\n",
        "    'Census_OEMNameIdentifier',\r\n",
        "    'DefaultBrowsersIdentifier'\r\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxQNNsAyTmsp"
      },
      "source": [
        "for variable in tqdm(frequency_encoded_variables):\r\n",
        "    freq_enc_dict = frequency_encoding(variable)\r\n",
        "    train[variable] = train[variable].map(lambda x: freq_enc_dict.get(x, np.nan))\r\n",
        "    test[variable] = test[variable].map(lambda x: freq_enc_dict.get(x, np.nan))\r\n",
        "    categorical_columns.remove(variable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtcinNzsTo0f"
      },
      "source": [
        "indexer = {}\r\n",
        "for col in tqdm(categorical_columns):\r\n",
        "    if col == 'MachineIdentifier': continue\r\n",
        "    _, indexer[col] = pd.factorize(train[col])\r\n",
        "    \r\n",
        "for col in tqdm(categorical_columns):\r\n",
        "    if col == 'MachineIdentifier': continue\r\n",
        "    train[col] = indexer[col].get_indexer(train[col])\r\n",
        "    test[col] = indexer[col].get_indexer(test[col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j81zF5bTqtw"
      },
      "source": [
        "train = reduce_mem_usage(train)\r\n",
        "test = reduce_mem_usage(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0-Wfwh9TsrE"
      },
      "source": [
        "train[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpNQdFziTutn"
      },
      "source": [
        "target = train['HasDetections']\r\n",
        "del train['HasDetections']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoUSYRt2Tw6W"
      },
      "source": [
        "param = {'num_leaves': 60,\r\n",
        "         'min_data_in_leaf': 60, \r\n",
        "         'objective':'binary',\r\n",
        "         'max_depth': -1,\r\n",
        "         'learning_rate': 0.1,\r\n",
        "         \"boosting\": \"gbdt\",\r\n",
        "         \"feature_fraction\": 0.8,\r\n",
        "         \"bagging_freq\": 1,\r\n",
        "         \"bagging_fraction\": 0.8 ,\r\n",
        "         \"bagging_seed\": 11,\r\n",
        "         \"metric\": 'auc',\r\n",
        "         \"lambda_l1\": 0.1,\r\n",
        "         \"random_state\": 133,\r\n",
        "         \"verbosity\": -1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3_l6TMhTzVJ"
      },
      "source": [
        "max_iter = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QahwRFpT1Jv"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofomdNCoT4gK"
      },
      "source": [
        "folds = KFold(n_splits=5, shuffle=True, random_state=15)\r\n",
        "oof = np.zeros(len(train))\r\n",
        "categorical_columns = [c for c in categorical_columns if c not in ['MachineIdentifier']]\r\n",
        "features = [c for c in train.columns if c not in ['MachineIdentifier']]\r\n",
        "predictions = np.zeros(len(test))\r\n",
        "start = time.time()\r\n",
        "feature_importance_df = pd.DataFrame()\r\n",
        "start_time= time.time()\r\n",
        "score = [0 for _ in range(folds.n_splits)]\r\n",
        "\r\n",
        "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\r\n",
        "    print(\"fold n°{}\".format(fold_))\r\n",
        "    trn_data = lgb.Dataset(train.iloc[trn_idx][features],\r\n",
        "                           label=target.iloc[trn_idx],\r\n",
        "                           categorical_feature = categorical_columns\r\n",
        "                          )\r\n",
        "    val_data = lgb.Dataset(train.iloc[val_idx][features],\r\n",
        "                           label=target.iloc[val_idx],\r\n",
        "                           categorical_feature = categorical_columns\r\n",
        "                          )\r\n",
        "\r\n",
        "    num_round = 10000\r\n",
        "    clf = lgb.train(param,\r\n",
        "                    trn_data,\r\n",
        "                    num_round,\r\n",
        "                    valid_sets = [trn_data, val_data],\r\n",
        "                    verbose_eval=100,\r\n",
        "                    early_stopping_rounds = 200)\r\n",
        "    \r\n",
        "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\r\n",
        "    \r\n",
        "    fold_importance_df = pd.DataFrame()\r\n",
        "    fold_importance_df[\"feature\"] = features\r\n",
        "    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\r\n",
        "    fold_importance_df[\"fold\"] = fold_ + 1\r\n",
        "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\r\n",
        "\r\n",
        "    # we perform predictions by chunks\r\n",
        "    initial_idx = 0\r\n",
        "    chunk_size = 1000000\r\n",
        "    current_pred = np.zeros(len(test))\r\n",
        "    while initial_idx < test.shape[0]:\r\n",
        "        final_idx = min(initial_idx + chunk_size, test.shape[0])\r\n",
        "        idx = range(initial_idx, final_idx)\r\n",
        "        current_pred[idx] = clf.predict(test.iloc[idx][features], num_iteration=clf.best_iteration)\r\n",
        "        initial_idx = final_idx\r\n",
        "    predictions += current_pred / min(folds.n_splits, max_iter)\r\n",
        "   \r\n",
        "    print(\"time elapsed: {:<5.2}s\".format((time.time() - start_time) / 3600))\r\n",
        "    score[fold_] = metrics.roc_auc_score(target.iloc[val_idx], oof[val_idx])\r\n",
        "    if fold_ == max_iter - 1: break\r\n",
        "        \r\n",
        "if (folds.n_splits == max_iter):\r\n",
        "    print(\"CV score: {:<8.5f}\".format(metrics.roc_auc_score(target, oof)))\r\n",
        "else:\r\n",
        "     print(\"CV score: {:<8.5f}\".format(sum(score) / max_iter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlZQutrjT9SQ"
      },
      "source": [
        "cols = (feature_importance_df[[\"feature\", \"importance\"]]\r\n",
        "        .groupby(\"feature\")\r\n",
        "        .mean()\r\n",
        "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\r\n",
        "\r\n",
        "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\r\n",
        "\r\n",
        "plt.figure(figsize=(14,25))\r\n",
        "sns.barplot(x=\"importance\",\r\n",
        "            y=\"feature\",\r\n",
        "            data=best_features.sort_values(by=\"importance\",\r\n",
        "                                           ascending=False))\r\n",
        "plt.title('LightGBM Features (avg over folds)')\r\n",
        "plt.tight_layout()\r\n",
        "plt.savefig('lgbm_importances.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEPsbZFZUAeo"
      },
      "source": [
        "sub_df = pd.DataFrame({\"MachineIdentifier\": test[\"MachineIdentifier\"].values})\r\n",
        "sub_df[\"HasDetections\"] = predictions\r\n",
        "sub_df[:10]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}